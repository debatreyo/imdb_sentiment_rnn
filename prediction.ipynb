{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f4589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4871c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d6829f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IMDB dataset word index\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# create index to word mapping\n",
    "index_to_word = {\n",
    "    index:word\n",
    "    for word, index in word_index.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65a3c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# load trained RNN model\n",
    "model = keras.models.load_model(\"simple_rnn_imdb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "663b97af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,027</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,313,027\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,025</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,313,025\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1fbc80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights (only first weight):\n",
      "First Weight: [[ 0.08890035  0.01897199 -0.3283632  ...  0.25740522  0.06664356\n",
      "  -0.11909889]\n",
      " [ 0.01722738 -0.04116703  0.02112949 ... -0.0389376   0.03882541\n",
      "  -0.07660983]\n",
      " [ 0.00109575 -0.04492613 -0.00833818 ... -0.07444874  0.06566562\n",
      "  -0.03874877]\n",
      " ...\n",
      " [-0.04128456 -0.00063791 -0.00796833 ... -0.00147981  0.00432313\n",
      "  -0.02321637]\n",
      " [-0.0381277  -0.02853669 -0.04319831 ...  0.0364357   0.01469409\n",
      "  -0.04312295]\n",
      " [ 0.02836713  0.03707549  0.04464354 ... -0.03479054 -0.0253838\n",
      "  -0.04229746]]\n",
      "Shape of first weight: (10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# get the trained model's weights\n",
    "weights = model.get_weights()\n",
    "print(\"Model weights (only first weight):\")\n",
    "for weight in weights:\n",
    "    print(f\"First Weight: {weight}\")\n",
    "    print(f\"Shape of first weight: {weight.shape}\") \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3371c4",
   "metadata": {},
   "source": [
    "## Helper Functions to Enable Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62244f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(encoded_review):\n",
    "    \"\"\"\n",
    "    Decode a review from encoded format to text.\n",
    "    \n",
    "    Args:\n",
    "        encoded_review (list): A list of integers representing the encoded review.\n",
    "    Returns:\n",
    "        str: The decoded review as a string.\n",
    "    \"\"\"\n",
    "    # Adjust the indices to match the IMDB dataset's word index\n",
    "    return \" \".join([index_to_word.get(i - 3, \"?\") for i in encoded_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3637bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, maxlen=500):\n",
    "    \"\"\"\n",
    "    Preprocess the input text for prediction.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to preprocess.\n",
    "        maxlen (int): The maximum length of the sequence.\n",
    "    Returns:\n",
    "        np.ndarray: The preprocessed text as a padded sequence.\n",
    "    \"\"\"\n",
    "    # Encode the text\n",
    "    words = text.lower()\n",
    "    # remove punctuation\n",
    "    words = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", words)\n",
    "    words = words.split()\n",
    "    encoded_text = [word_index.get(word, 2) + 3 for word in words] # Adjusting for IMDB's word index\n",
    "    # Pad the sequence to the maximum length\n",
    "    padded_text = pad_sequences([encoded_text], maxlen=maxlen, padding=\"pre\")\n",
    "\n",
    "    return padded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba0dde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review_sentiment(review):\n",
    "    \"\"\"\n",
    "    Predict the sentiment of a review.\n",
    "    \n",
    "    Args:\n",
    "        encoded_review (list): A list of integers representing the encoded review.\n",
    "    Returns:\n",
    "        str: The predicted sentiment (\"Positive\" or \"Negative\").\n",
    "    \"\"\"\n",
    "    # preprocess the review\n",
    "    pre_processed_review = preprocess_text(review)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(pre_processed_review)\n",
    "    \n",
    "    # prediction score\n",
    "    score = prediction[0][0]\n",
    "\n",
    "    # Return sentiment based on prediction\n",
    "    return f\"Movie revie: {review}\\n\\nThis is a Positive review. :)\\n\\n Sentiment score: {score}\" if prediction[0][0] > 0.5 else f\"Movie revie: {review}\\n\\nThis is a Negative review. :(\\n\\n Sentiment score: {score}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e32132b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "Movie revie: This movie was fantastic! I loved the plot and the acting was superb.\n",
      "\n",
      "This is a Positive review. :)\n",
      "\n",
      " Sentiment score: 0.7645069360733032\n",
      "--------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Movie revie: This was bad!!! :( Did not enjoy the movie at all. The plot was boring and the acting was terrible.\n",
      "\n",
      "This is a Negative review. :(\n",
      "\n",
      " Sentiment score: 0.06337247788906097\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# test the prediction function\n",
    "test_review_positive = \"This movie was fantastic! I loved the plot and the acting was superb.\"\n",
    "\n",
    "test_review_negative = \"This was bad!!! :( Did not enjoy the movie at all. The plot was boring and the acting was terrible.\"\n",
    "\n",
    "test_review = [test_review_positive,\n",
    "                test_review_negative]\n",
    "\n",
    "for review in test_review:\n",
    "    print(predict_review_sentiment(review))\n",
    "    print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b9edf9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10882a86",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
